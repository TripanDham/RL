{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: jciwwtvy\n",
      "Sweep URL: https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 11xr1x9i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0004853370245948945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdate_every: 75\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshobhith-v\u001b[0m (\u001b[33mrl_shobhith\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Shobhith Vadlamudi\\Desktop\\rl2\\RL\\wandb\\run-20240404_121455-11xr1x9i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/11xr1x9i/workspace' target=\"_blank\">deep-sweep-1</a></strong> to <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/11xr1x9i/workspace' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/11xr1x9i/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "1000\n",
      "128\n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shobhith Vadlamudi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec81691db6454c35b25af69f07cdea3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>regret</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>regret</td><td>33320.78085</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-sweep-1</strong> at: <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/11xr1x9i/workspace' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/11xr1x9i/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240404_121455-11xr1x9i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rg9645jl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.007999003114992527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdate_every: 75\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Shobhith Vadlamudi\\Desktop\\rl2\\RL\\wandb\\run-20240404_121708-rg9645jl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/rg9645jl/workspace' target=\"_blank\">lyric-sweep-2</a></strong> to <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/rg9645jl/workspace' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/rg9645jl/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "1000\n",
      "256\n",
      "75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f4496ec2df48d2ba06e07d925915cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.006 MB uploaded\\r'), FloatProgress(value=0.2267669172932331, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>regret</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>regret</td><td>41359.71132</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-2</strong> at: <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/rg9645jl/workspace' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/rg9645jl/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240404_121708-rg9645jl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ly55qto2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_size: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.009918273766220283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdate_every: 75\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Shobhith Vadlamudi\\Desktop\\rl2\\RL\\wandb\\run-20240404_121812-ly55qto2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/ly55qto2/workspace' target=\"_blank\">amber-sweep-3</a></strong> to <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/ly55qto2/workspace' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/ly55qto2/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "100000\n",
      "64\n",
      "75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e931471e361b4753a7547d31d6b2acc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>regret</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>regret</td><td>40248.57521</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">amber-sweep-3</strong> at: <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/ly55qto2/workspace' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/ly55qto2/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240404_121812-ly55qto2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sbr5ymk9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 7.455082452151809e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tupdate_every: 100\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Shobhith Vadlamudi\\Desktop\\rl2\\RL\\wandb\\run-20240404_121916-sbr5ymk9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/sbr5ymk9/workspace' target=\"_blank\">olive-sweep-4</a></strong> to <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/sweeps/jciwwtvy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/sbr5ymk9/workspace' target=\"_blank\">https://wandb.ai/rl_shobhith/dueling_mean_cartpole/runs/sbr5ymk9/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "1000\n",
      "128\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import wandb\n",
    "\n",
    "GAMMA=0.99\n",
    "\n",
    "class QNetwork1(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=128, fc2_units=64):\n",
    "        super(QNetwork1, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc_advantage = nn.Linear(fc2_units, action_size)\n",
    "        self.fc_value = nn.Linear(fc2_units, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        value = self.fc_value(x)\n",
    "        advantage = self.fc_advantage(x)\n",
    "        Q_values = value + (advantage - advantage.mean(dim=1, keepdim=True))\n",
    "        return Q_values\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "\n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class TutorialAgent1:\n",
    "    def __init__(self, state_size, action_size, seed, lr, update_every, buffer_size, batch_size):\n",
    "        self.state_size = state_size\n",
    "        print(update_every)\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "        self.qnetwork_local = QNetwork1(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork1(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=lr)\n",
    "        self.memory = ReplayBuffer(action_size, buffer_size, batch_size, seed)\n",
    "        self.t_step = 0\n",
    "        self.update_every = update_every\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        if len(self.memory) >= self.batch_size:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "        self.t_step = (self.t_step + 1) % self.update_every\n",
    "        if self.t_step == 0:\n",
    "            self.qnetwork_target.load_state_dict(self.qnetwork_local.state_dict())\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        Q_targets_next = self.qnetwork_target(next_states)\n",
    "        next_state_values = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        Q_targets = rewards + (gamma * next_state_values * (1 - dones))\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "def dqn(agent, env, n_episodes=10000, max_t=500, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    scores_window = deque(maxlen=100)\n",
    "    all_scores = np.array([])\n",
    "    moving_avg_scores = np.array([])\n",
    "    eps = eps_start\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state,_ = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, truncated,_ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done or truncated:\n",
    "                break\n",
    "        scores_window.append(score)\n",
    "        all_scores = np.append(all_scores, score)\n",
    "        eps = max(eps_end, eps_decay * eps)\n",
    "        moving_avg_scores = np.append(moving_avg_scores, np.mean(scores_window))\n",
    "        if i_episode == 250:\n",
    "            break\n",
    "    return moving_avg_scores, True\n",
    "\n",
    "def train_agent(lr, update_every, buffer_size, batch_size):\n",
    "    env = gym.make('CartPole-v1')\n",
    "    print(update_every)\n",
    "    print(buffer_size)\n",
    "    print(batch_size)\n",
    "    state_shape = env.observation_space.shape[0]\n",
    "    action_shape = env.action_space.n\n",
    "    agent = TutorialAgent1(state_size=state_shape, action_size=action_shape, seed=0, lr=lr,\n",
    "                           update_every=update_every, buffer_size=buffer_size, batch_size=batch_size)\n",
    "    all_scores_1, _ = dqn(agent, env)\n",
    "    regret = 0\n",
    "    for i in all_scores_1:\n",
    "        if i > 195:\n",
    "            break\n",
    "        else:\n",
    "            regret += 195 - i\n",
    "    return regret\n",
    "\n",
    "def run_training():\n",
    "    config_defaults = {\n",
    "        \"lr\": 5e-4,\n",
    "        \"update_every\": 50,\n",
    "        \"buffer_size\": 1e5,\n",
    "        \"batch_size\": 64\n",
    "    }\n",
    "    config = wandb.init(config=config_defaults, project=\"dueling_mean_cartpole_2\")\n",
    "    lr = config.config[\"lr\"]\n",
    "    update_every = config.config['update_every']\n",
    "    batch_size = config.config[\"batch_size\"]\n",
    "    buffer_size = config.config[\"buffer_size\"]\n",
    "    regret = train_agent(lr, update_every, buffer_size, batch_size)\n",
    "    wandb.log({\"regret\": regret})\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"regret\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"min\": 1e-5, \"max\": 1e-2},\n",
    "        \"update_every\": {\"values\": [20, 50, 75, 100]},\n",
    "        \"buffer_size\": {\"values\": [1e2, 1e3, 1e5]},\n",
    "        \"batch_size\": {\"values\": [64, 128, 256]}\n",
    "    },\n",
    "    \"project\": \"dueling_mean_cartpole\",\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 3,\n",
    "        \"max_iter\": 100\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)\n",
    "wandb.agent(sweep_id, function=run_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
